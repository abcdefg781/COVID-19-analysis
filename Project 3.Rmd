---
title: 'Newton Raphson'
output:
  pdf_document
editor_options: 
  chunk_output_type: console
---

```{r include = FALSE}
library(tidyverse)
library(ggplot2)
library(lubridate)
library(anytime)
```

```{r}
covid = read.csv(file.path(getwd(), "covid_final.csv")) %>%
  mutate(date = lubridate::parse_date_time(x = date,
                                           orders = c("m/d/y", "m-d-Y")),
         t = as.numeric(difftime(date, min(date), units = "days"))) %>% 
  filter(country_region == "US", province_state == "New York") %>% 
  filter(date > "2020-03-15") %>% filter(date < "2020-03-31")
```

#Log-likelihood function

```{r}
func = function(t, y, betavec) {
  a = betavec[1]
  b = betavec[2]
  c = betavec[3]
  # Expu
  expu = exp(-b * (t - c))
  
  # Log-likelihood
  loglik = sum(log(a) - log(1 + expu))
  
  # Gradient
  grad = vector(mode = "numeric", 3)
  
  grad[1] = sum(1/a)
  grad[2] = sum((t-c) / (1 + expu))
  grad[3] = sum(b / (1 + expu))
  
  # Hessian Matrix
  hess = matrix(data = NA, nrow = 3, ncol = 3)
  hess[1,1] = sum(- 1 / a^2)
  hess[2,2] = sum(((1 + expu) * (-(t - c)^2 * expu) + (t - c)^2 * expu * exp(-2)) / (1 + expu)^2)
  hess[3,3] = sum(((1 + expu) * (-b^2 * expu) + b^2 * expu * exp(-2)) / (1 + expu)^2)
  
  # Remainder of hessian matrix
  for (i in 1:3) {
    for (j in 1:3) {
      if (i == j) {
        next()
      } else if (i == 1 | j == 1) {
        hess[i,j] = 0
      } else {
        hess[i,j] = sum((-b * (t - c) * exp(-2) * expu - b^2 * expu * (1 + expu)) / (1 + expu)^2)
      }
    }
  }
  
  return(list(loglik = loglik, grad = grad, Hess = hess)) 
}
```


```{r include = FALSE,warning = FALSE, message = FALSE}
#### Newton-Raphson with gradient descent and step-halving
NewtonRaphson <- function(y, t, func, start, tol=1e-7, maxiter = 200) {
  i <- 0
  cur <- start
  x = as.matrix(x)
  stuff <- func(t,y,cur)
  res <- c(0, stuff$loglik, cur)
  prevloglik <- -Inf
  while(i < maxiter && abs(stuff$loglik - prevloglik) > tol) {
    i <- i + 1
    prevloglik <- stuff$loglik
    prev <- cur
    grad <- stuff$grad
    hess <- stuff$Hess
    
    #gradient descent 
    if(t(grad) %*% hess %*% grad > 0){#positive definite matrix
    inv.hess = 
      solve(hess - (max(diag(hess))+100)*diag(nrow(hess)))} #make positive definite matrix negative definite
    else 
    {inv.hess <- solve(hess)}
    
    cur <- prev - inv.hess%*%grad
    stuff <- func(y, x, cur)
    
    #step-halving
    step = 0
    while (prevloglik > stuff$loglik){#moving too far -> halve step
    step = step + 1 
    cur <- prev - (1/2)^step * inv.hess%*%grad
    stuff <- func(y, x, cur)
    }
  res <- rbind(res, c(i, stuff$loglik, cur))
  }
  return(res)
  }
```

```{r}
func(covid$confirmed_cases, covid$t, c(10000,1.5,200))
NewtonRaphson(covid$confirmed_cases, covid$t, func, c(10000,1.5,100))
```





# Task 2: Clustering your fitted curves

clustering is an effective data exploring tools; It helps develop hypothesis and identify potential risk factors;  Apply K-mean and Guassian mixture model (with EM algorithm) to cluster the fitted parameters $(\hat{a},\hat{b},\hat{c})$; Which algorithm does a better job in clustering those curves? Are the resulting clusters related to geogrpahic regions, or the starting timeing of the local virus speading, or the resources of the regions? You may use external informations to help understand the clusters, i.e. find plausible explanations why some regions have similar $(a, b,c)$?




# Task 3: Write a summary report to share your findings;

```{r}
#Includes uour R codes
```

