---
title: "task-2"
author: "Ngoc Duong"
date: "4/23/2020"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(plotly)
```


```{r}
library(MASS)
library(tidyverse)
#fake data 
set.seed(123123)
Sigma1 = matrix(c(1, 0.5, 0.5,0.5,1,0.5,0.5, 0.5,1), ncol = 3, nrow = 3)
x1 = mvrnorm(n = 200, mu = c(0 ,0, 0), Sigma1)
Sigma2 = matrix(c(2, 0.5, 0.5,0.5,2,0.5,0.5, 0.5,2), ncol = 3, nrow = 3)
x2 = mvrnorm(n = 200, mu = c(1, 3, 2), Sigma2)
Sigma3 = matrix(c(3, 0.5, 0.5,0.5,3,0.5,0.5, 0.5,3), ncol = 3, nrow = 3)
x3 = mvrnorm(n = 200, mu = c(4 ,1, -2), Sigma3)
data =  rbind(x1, x2, x3)
#standardize data
standardize = function(col) {
  mean = mean(col)
  stdev = sd(col)
  return((col - mean)/stdev)
}
data = as.tibble(data) %>% map_df(.x = ., standardize)
```


For each data point x, compute d, the distance between x and the nearest center that has already been chosen.
Choose one new data point at random as a new center, using a weighted probability distribution where a point x is chosen with probability proportional to d^2
Repeat steps 2 and 3 until k centers have been chosen.

```{r}
#partition of data such that squared error between empirical mean and points in each cluster/partition is minimized
km_func <- function(data, k){
  p <- ncol(data)  # number of parameters
  n <- nrow(data)  # number of observations
  diff = 1
  iter = 0
  itermax = 50
  while(diff > 1e-4 && iter <= itermax){
    #initial centroids
    if(iter == 0){
      centroid = data[sample(nrow(data), k),]
      centroid_mem = centroid
    }

    #assign to cluster 
    d = sapply(1:k, function(c) sapply(1:n, function(i) {sum((centroid[c,] - data[i,])^2)}))
    
    cluster = apply(d, 1, which.min)
    
    #recalculate cluster 
    centroid = t(sapply(1:k, 
                         function(c) {apply(data[cluster == c,], 2, mean)}
                         ))
    
    #recalculate distance
    diff = sum((centroid - centroid_mem)^2)
    iter = iter + 1 
    centroid_mem = centroid
  }
  return(list(centroid = centroid, cluster = cluster))
}
```

```{r}
#test on simulated data 
km <- km_func(data, 3)
colnames(data) = c("a","b","c")
data_new = cbind(data, cluster = km$cluster)
plot_ly(x=data_new[,1], y=data_new[,2], z=data_new[,3], type="scatter3d", mode="markers", color = data_new[,4])
```


```{r}
#import data
param_df = read_csv("./parameter_estimates.csv")[,-1] %>% as.data.frame()

#standardize data
param_names = c("a","b","c")
param_standard = NULL
for (i in 2:4) {
col = (param_df[,i] - mean(as.vector(param_df[,i])))/sd(as.vector(param_df[,i]))
param_standard = cbind(param_standard, col)
}

# run K-means
km <- km_func(param_standard, 3)
param_standard = cbind(param_df$region, param_standard)
colnames(param_standard) <- c("region","a","b","c")
param_final = cbind(param_standard, cluster = km$cluster) %>% as_tibble() %>% 
  mutate(a = as.numeric(a),
         b = as.numeric(b),
         c = as.numeric(c)) %>% group_by(cluster) %>% arrange(desc(cluster))

#plot
plot_ly(x=param_final$a, y=param_final$b, z=param_final$c, 
        type="scatter3d", mode="markers", color = param_final$cluster)
```

