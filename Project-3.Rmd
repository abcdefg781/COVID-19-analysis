---
title: 'Project 3: Analyses of daily COVID-19 cases across nations'
output:
  pdf_document
---


The pandemic of COVID-19 is the biggest challenge that the world is facing right now. Our lifes are all deeply affected by this public health crisis.  The White House has pulled together multiple open research data sets, and called for data scientist to assist the modeling  of the growth trajecties of confirmed cases across the worlds, and to help prediction future cases and to identify risk factors. I would like to encourage you to be part of the force; 

```{r include = FALSE}
library(tidyverse)
library(ggplot2)
```

The attached covid19-1.csv, is a subset of the open data, which recorded the following variables:

**Id:** Record ID

**Province/State:** The lcoal state/province of the record; 54% records do not have this info;

**Country/Region:** The country/regionoof the record;

**Lat:** Lattudiute of the record;

**Long:** Longitude of the record;

**Date:** Date of the record; from Jan 21 to March 23; 

**ConfirmedCases:** The number of confirme case on that day;

**Fatalities:** The number of death on that day;



# Task 1: Fit a logistic curve to the cumulative confirmed cases in each region;

Logisitc curves could be one way to model the trajectory of cumulative cases;  It is a parametric function with the form 
$$f(t) = \frac{a}{ 1+ exp\{-b(t-c)\}},$$
where $t$ is the days since the first infection; $a$ is the upper bound, i.e. the maxium number of cases a region can reach, $b$ is growth rate, and $c$ is the mid-point, where the curve changes from convex to concave; Each curve is uniquely defined by $(a,b,c)$. By design a logistic curve increases exponentially at begining and slows down at the end; 


**Task 1.1** Develop an optmization algorithm to fit a logisitc curve to each region, and find a way to visualize your fitted curves effectively;   What you learn from your fitted models? e.g. how many regions have passed the midpoint? how many regions are approaching to the end of the virus speading; Which regions have faster growth rates and which regions have more "flat" growth? 

```{r}
covid19 = read_csv("covid19-1.csv")
```

```{r}
nPL3 <- function(bottom, top, xmid, scal, s,  X){
    yfit <- (top)/(1+10^((xmid-X)*scal))
    return(yfit)
}
```

$f(x) = 0 + \frac{d-0}{1+\exp(b(\log(x)-e))}$
e is inflection point 


```{r}
library(drc)
## Fitting model with lower limit equal 0
ryegrass.model1 <- drm(rootl ~ conc, data = ryegrass, fct = LL.3())
summary(ryegrass.model1)
## Fitting binomial response
##  with non-zero control response

## Example dataset from Finney (1971) - example 19
logdose <- c(2.17, 2,1.68,1.08,-Inf,1.79,1.66,1.49,1.17,0.57)
n <- c(142,127,128,126,129,125,117,127,51,132)
r <- c(142,126,115,58,21,125,115,114,40,37)
treatment <- factor(c("w213","w213","w213","w213",
"w214","w214","w214","w214","w214","w214"))
# Note that the control is included in one of the two treatment groups
finney.ex19 <- data.frame(logdose, n, r, treatment)

## Fitting model where the lower limit is estimated
fe19.model1 <- drm(r/n~logdose, treatment, weights = n, data = finney.ex19, logDose = 10, fct = LL.3u(), type="binomial", pmodels = data.frame(treatment, 1, treatment))

summary(fe19.model1)
modelFit(fe19.model1)
plot(fe19.model1, ylim = c(0, 1.1), bp = -1, broken = TRUE, legendPos = c(0, 1))
abline(h = 1, lty = 2)
```




# Task 2: Clustering your fitted curves

clustering is an effective data exploring tools; It helps develop hypothesis and identify potential risk factors;  Apply K-mean and Guassian mixture model (with EM algorithm) to cluster the fitted parameters $(\hat{a},\hat{b},\hat{c})$; Which algorithm does a better job in clustering those curves? Are the resulting clusters related to geogrpahic regions, or the starting timeing of the local virus speading, or the resources of the regions? You may use external informations to help understand the clusters, i.e. find plausible explanations why some regions have similar $(a, b,c)$?

```{r}
#Method : EM algorithm
#Example: Data of mortality of Tribolium castaneum beetle
#---------------------------------------------------------
Y<-c(15,24,26,24,29,29)
N<-c(50,49,50,50,50,49)
X<-c(1.08,1.16,1.21,1.26,1.31,1.35)
#EM algorithm
estep<-function(Y,N,X,theta) {
  m<-theta[1]+theta[2]*X
  T1<-sum(N*m+Y*dnorm(m)/pnorm(m)-(N-Y)*dnorm(-m)/pnorm(-m))
  T2<-sum((N*m+Y*dnorm(m)/pnorm(m)-(N-Y)*dnorm(-m)/pnorm(-m))*X)
	c(T1,T2)
}
mstep<-function(T,N,X) {
	n<-sum(N)
  b<-(T[2]-T[1]*N%*%X/n)/(N%*%((X-N%*%X/n)^2))
	a<-T[1]/n-b*N%*%X/n
	c(a,b)
}
#Application to data
I<-25
p<-c(0,0)
for (i in 1:I) {
  T<-estep(Y,N,X,p)
  p<-mstep(T,N,X)
}
p
#Fit restricted model: b=0
#Modified M-step
mstepr<-function(T,N,X) {
	n<-sum(N)
  b<-0
	a<-T[1]/n
	c(a,b)
}
#Application to data
I<-25
p0<-c(0,0)
for (i in 1:I) {
  T<-estep(Y,N,X,p)
  p0<-mstepr(T,N,X)
}
p0
#Likelihood ratio test for b=0
loglik<-function(Y,N,X,p) {
  m<-p[1]+p[2]*X
	sum(Y*log(pnorm(m))+(N-Y)*log(1-pnorm(m)))
}
S<-2*(loglik(Y,N,X,p)-loglik(Y,N,X,p0))
#Value of test statistic
S
#5% critical value
qchisq(0.95,1)
#p value
1-pchisq(S,1)
#----------------------------------#Method : EM algorithm
#Example: Data of mortality of Tribolium castaneum beetle
#---------------------------------------------------------
Y<-c(15,24,26,24,29,29)
N<-c(50,49,50,50,50,49)
X<-c(1.08,1.16,1.21,1.26,1.31,1.35)
#EM algorithm
estep<-function(Y,N,X,theta) {
  m<-theta[1]+theta[2]*X
  T1<-sum(N*m+Y*dnorm(m)/pnorm(m)-(N-Y)*dnorm(-m)/pnorm(-m))
  T2<-sum((N*m+Y*dnorm(m)/pnorm(m)-(N-Y)*dnorm(-m)/pnorm(-m))*X)
	c(T1,T2)
}
mstep<-function(T,N,X) {
	n<-sum(N)
  b<-(T[2]-T[1]*N%*%X/n)/(N%*%((X-N%*%X/n)^2))
	a<-T[1]/n-b*N%*%X/n
	c(a,b)
}
#Application to data
I<-25
p<-c(0,0)
for (i in 1:I) {
  T<-estep(Y,N,X,p)
  p<-mstep(T,N,X)
}
p
#Fit restricted model: b=0
#Modified M-step
mstepr<-function(T,N,X) {
	n<-sum(N)
  b<-0
	a<-T[1]/n
	c(a,b)
}
#Application to data
I<-25
p0<-c(0,0)
for (i in 1:I) {
  T<-estep(Y,N,X,p)
  p0<-mstepr(T,N,X)
}
p0
#Likelihood ratio test for b=0
loglik<-function(Y,N,X,p) {
  m<-p[1]+p[2]*X
	sum(Y*log(pnorm(m))+(N-Y)*log(1-pnorm(m)))
}
S<-2*(loglik(Y,N,X,p)-loglik(Y,N,X,p0))
#Value of test statistic
S
#5% critical value
qchisq(0.95,1)
#p value
1-pchisq(S,1)
```



# Task 3: Write a summary report to share your findings;

```{r}
#Includes uour R codes
```

